{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib as plt\nimport seaborn as sns\nfrom time import time\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom torch.utils.data import random_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchmetrics.classification import MultilabelF1Score\nfrom torchmetrics.classification import MultilabelAccuracy\nfrom transformers import BertModel, BertTokenizer\nfrom Bio import SeqIO","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-10T16:14:35.013485Z","iopub.execute_input":"2023-06-10T16:14:35.013950Z","iopub.status.idle":"2023-06-10T16:14:35.022211Z","shell.execute_reply.started":"2023-06-10T16:14:35.013891Z","shell.execute_reply":"2023-06-10T16:14:35.020674Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\nnp.random.seed(42)\ntorch.cuda.manual_seed_all(42)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:35.026728Z","iopub.execute_input":"2023-06-10T16:14:35.027085Z","iopub.status.idle":"2023-06-10T16:14:35.037435Z","shell.execute_reply.started":"2023-06-10T16:14:35.027056Z","shell.execute_reply":"2023-06-10T16:14:35.036138Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class config:\n    num_labels = 500\n    n_epochs = 25\n    batch_size = 128\n    lr = 0.001\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    embeds_dim = 1024","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:35.039767Z","iopub.execute_input":"2023-06-10T16:14:35.040466Z","iopub.status.idle":"2023-06-10T16:14:35.049696Z","shell.execute_reply.started":"2023-06-10T16:14:35.040423Z","shell.execute_reply":"2023-06-10T16:14:35.048579Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class paths:\n    train_ids = \"/kaggle/input/protbert-embeddings-for-cafa5/train_ids.npy\"    \n    train_embeddings = \"/kaggle/input/protbert-embeddings-for-cafa5/train_embeddings.npy\"\n    test_ids = \"/kaggle/input/protbert-embeddings-for-cafa5/test_ids.npy\"\n    test_embeddings = \"/kaggle/input/protbert-embeddings-for-cafa5/test_embeddings.npy\"\n    train_labels_path = \"/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\"\n    train_targets_path = \"/kaggle/input/cafa5-label-vectors-numpy/train_targets_top500.npy\"","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:35.051499Z","iopub.execute_input":"2023-06-10T16:14:35.052167Z","iopub.status.idle":"2023-06-10T16:14:35.067988Z","shell.execute_reply.started":"2023-06-10T16:14:35.052127Z","shell.execute_reply":"2023-06-10T16:14:35.066965Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class CustomProteinDataset(Dataset):\n    def __init__(self, train=True):\n        super(CustomProteinDataset).__init__()\n        self.train=train\n        if train:\n            embeds = np.load(paths.train_embeddings)\n            ids = np.load(paths.train_ids)\n        else:\n            embeds = np.load(paths.test_embeddings)\n            ids = np.load(paths.test_ids)\n        \n        embeds_list = []\n        for l in range(embeds.shape[0]):\n            embeds_list.append(embeds[l,:])\n        self.df = pd.DataFrame(data={\"EntryID\": ids, \"embed\" : embeds_list})\n        \n        if train:\n            self.labels = np.load(paths.train_targets_path)\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        embed = torch.tensor(self.df.iloc[index][\"embed\"], dtype = torch.float32)\n        if self.train:\n            targets = torch.tensor(self.labels[index, :], dtype = torch.float32)\n            return embed, targets\n        else:\n            id = self.df.iloc[index][\"EntryID\"]\n            return embed, id","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:35.070794Z","iopub.execute_input":"2023-06-10T16:14:35.071266Z","iopub.status.idle":"2023-06-10T16:14:35.083195Z","shell.execute_reply.started":"2023-06-10T16:14:35.071224Z","shell.execute_reply":"2023-06-10T16:14:35.081971Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomProteinDataset()\ntest_dataset = CustomProteinDataset(train=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:35.084206Z","iopub.execute_input":"2023-06-10T16:14:35.084567Z","iopub.status.idle":"2023-06-10T16:14:39.094914Z","shell.execute_reply.started":"2023-06-10T16:14:35.084530Z","shell.execute_reply":"2023-06-10T16:14:39.093709Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:39.096369Z","iopub.execute_input":"2023-06-10T16:14:39.096706Z","iopub.status.idle":"2023-06-10T16:14:39.103524Z","shell.execute_reply.started":"2023-06-10T16:14:39.096678Z","shell.execute_reply":"2023-06-10T16:14:39.102472Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"142246"},"metadata":{}}]},{"cell_type":"code","source":"class MultiLayerPerceptron(torch.nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(MultiLayerPerceptron, self).__init__()\n        self.linear1 = torch.nn.Linear(input_dim, 1012)\n        self.activation1 = torch.nn.ReLU()\n        self.linear2 = torch.nn.Linear(1012, 712)\n        self.activation2 = torch.nn.ReLU()\n        self.linear3 = torch.nn.Linear(712, num_classes)\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.activation1(x)\n        x = self.linear2(x)\n        x = self.activation2(x)\n        x = self.linear3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:39.104789Z","iopub.execute_input":"2023-06-10T16:14:39.105106Z","iopub.status.idle":"2023-06-10T16:14:39.116564Z","shell.execute_reply.started":"2023-06-10T16:14:39.105075Z","shell.execute_reply":"2023-06-10T16:14:39.115407Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class CNN1D(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels=1, out_channels=3, kernel_size=3, dilation=1, padding=1, stride=1)\n        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv1d(in_channels=3, out_channels=8, kernel_size=3, dilation=1, padding=1, stride=1)\n        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(in_features=int(8 * input_dim/4), out_features=128)\n        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n\n    def forward(self, x):\n        x = x.reshape(x.shape[0], 1, x.shape[1])\n        x = self.pool1(nn.functional.relu(self.conv1(x)))\n        x = self.pool2(nn.functional.relu(self.conv2(x)))\n        x = torch.flatten(x, 1)\n        x = nn.functional.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:39.117828Z","iopub.execute_input":"2023-06-10T16:14:39.118216Z","iopub.status.idle":"2023-06-10T16:14:39.133934Z","shell.execute_reply.started":"2023-06-10T16:14:39.118187Z","shell.execute_reply":"2023-06-10T16:14:39.132737Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def train(model_type=\"linear\", train_size=0.9):\n    train_set, val_set = random_split(train_dataset, lengths = [int(len(train_dataset)*train_size), len(train_dataset)-int(len(train_dataset)*train_size)])\n    train_dataloader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True)\n    val_dataloader = DataLoader(val_set, batch_size=config.batch_size, shuffle=True)\n    \n    if model_type == \"linear\":\n        model = MultiLayerPerceptron(input_dim=config.embeds_dim, num_classes=config.num_labels).to(config.device)\n    if model_type == \"convolutional\":\n        model = CNN1D(input_dim=config.embeds_dim, num_classes=config.num_labels).to(config.device)\n        \n    optimizer = torch.optim.Adam(model.parameters(), lr = config.lr)\n    scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=1)\n    CrossEntropy = torch.nn.CrossEntropyLoss()\n    f1_score = MultilabelF1Score(num_labels=config.num_labels).to(config.device)\n    n_epochs = config.n_epochs\n    \n    train_loss_history=[]\n    val_loss_history=[]\n    \n    train_f1score_history=[]\n    val_f1score_history=[]\n    \n    for epoch in range(n_epochs):\n        print(\"EPOCH \", epoch+1)\n        ## TRAIN PHASE :\n        losses = []\n        scores = []\n        for embed, targets in tqdm(train_dataloader):\n            embed, targets = embed.to(config.device), targets.to(config.device)\n            optimizer.zero_grad()\n            preds = model(embed)\n            loss= CrossEntropy(preds, targets)\n            score=f1_score(preds, targets)\n            losses.append(loss.item()) \n            scores.append(score.item())\n            loss.backward()\n            optimizer.step()\n        avg_loss = np.mean(losses)\n        avg_score = np.mean(scores)\n        print(\"Running Average TRAIN Loss : \", avg_loss)\n        print(\"Running Average TRAIN F1-Score : \", avg_score)\n        train_loss_history.append(avg_loss)\n        train_f1score_history.append(avg_score)\\\n        \n        losses = []\n        scores = []\n        for embed, targets in val_dataloader:\n            embed, targets = embed.to(config.device), targets.to(config.device)\n            preds = model(embed)\n            loss= CrossEntropy(preds, targets)\n            score=f1_score(preds, targets)\n            losses.append(loss.item())\n            scores.append(score.item())\n        avg_loss = np.mean(losses)\n        avg_score = np.mean(scores)\n        print(\"Running Average VAL Loss : \", avg_loss)\n        print(\"Running Average VAL F1-Score : \", avg_score)\n        val_loss_history.append(avg_loss)\n        val_f1score_history.append(avg_score)\n        \n        scheduler.step(avg_loss)\n        print(\"\\n\")\n        \n    print(\"TRAINING FINISHED\")\n    print(\"FINAL TRAINING SCORE : \", train_f1score_history[-1])\n    print(\"FINAL VALIDATION SCORE : \", val_f1score_history[-1])\n    \n    losses_history = {\"train\" : train_loss_history, \"val\" : val_loss_history}\n    scores_history = {\"train\" : train_f1score_history, \"val\" : val_f1score_history}\n    \n    return model, losses_history, scores_history","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:39.137099Z","iopub.execute_input":"2023-06-10T16:14:39.137515Z","iopub.status.idle":"2023-06-10T16:14:39.154885Z","shell.execute_reply.started":"2023-06-10T16:14:39.137482Z","shell.execute_reply":"2023-06-10T16:14:39.152737Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model, losses_history, scores_history = train(model_type=\"linear\", train_size=0.95)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:14:39.157222Z","iopub.execute_input":"2023-06-10T16:14:39.158572Z","iopub.status.idle":"2023-06-10T16:34:02.287648Z","shell.execute_reply.started":"2023-06-10T16:14:39.158524Z","shell.execute_reply":"2023-06-10T16:34:02.285923Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"EPOCH  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  138.00875971534035\nRunning Average TRAIN F1-Score :  0.10431985564487563\nRunning Average VAL Loss :  134.5035569327218\nRunning Average VAL F1-Score :  0.13277065607586078\n\n\nEPOCH  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:46<00:00, 22.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  135.07629364187068\nRunning Average TRAIN F1-Score :  0.14090815848304014\nRunning Average VAL Loss :  132.99446432931083\nRunning Average VAL F1-Score :  0.14797663063343083\n\n\nEPOCH  3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:46<00:00, 22.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  133.96682144656324\nRunning Average TRAIN F1-Score :  0.1535308060560827\nRunning Average VAL Loss :  132.1038383756365\nRunning Average VAL F1-Score :  0.156761730621968\n\n\nEPOCH  4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  133.20018368056327\nRunning Average TRAIN F1-Score :  0.16114157686630884\nRunning Average VAL Loss :  131.64523492540633\nRunning Average VAL F1-Score :  0.16388671632323945\n\n\nEPOCH  5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:46<00:00, 22.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  132.5856273535526\nRunning Average TRAIN F1-Score :  0.1672656626906246\nRunning Average VAL Loss :  131.29761477879114\nRunning Average VAL F1-Score :  0.1671999583819083\n\n\nEPOCH  6\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  132.09052466623712\nRunning Average TRAIN F1-Score :  0.17228831706399267\nRunning Average VAL Loss :  131.0025987625122\nRunning Average VAL F1-Score :  0.16889282715107715\n\n\nEPOCH  7\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  131.59908506364533\nRunning Average TRAIN F1-Score :  0.17653172062427708\nRunning Average VAL Loss :  130.84913390023368\nRunning Average VAL F1-Score :  0.1739802443023239\n\n\nEPOCH  8\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:46<00:00, 22.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  131.2212935072003\nRunning Average TRAIN F1-Score :  0.18082432767771411\nRunning Average VAL Loss :  130.12302221570695\nRunning Average VAL F1-Score :  0.17921998990433557\n\n\nEPOCH  9\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:46<00:00, 22.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  130.7778364239317\nRunning Average TRAIN F1-Score :  0.18514902827640375\nRunning Average VAL Loss :  129.99260098593575\nRunning Average VAL F1-Score :  0.179684135264584\n\n\nEPOCH  10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:46<00:00, 22.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  130.39919090270996\nRunning Average TRAIN F1-Score :  0.18889884694451184\nRunning Average VAL Loss :  130.4820717402867\nRunning Average VAL F1-Score :  0.1816998893128974\n\n\nEPOCH  11\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  130.05998239372715\nRunning Average TRAIN F1-Score :  0.19293708491110892\nRunning Average VAL Loss :  130.05918734414237\nRunning Average VAL F1-Score :  0.18423451536468097\n\n\nEPOCH  12\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  128.61242331880513\nRunning Average TRAIN F1-Score :  0.20184582333560241\nRunning Average VAL Loss :  129.14695971352714\nRunning Average VAL F1-Score :  0.1901145726442337\n\n\nEPOCH  13\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  128.37160655946442\nRunning Average TRAIN F1-Score :  0.2043950503099371\nRunning Average VAL Loss :  129.09178039005823\nRunning Average VAL F1-Score :  0.18989254693899835\n\n\nEPOCH  14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  128.26470320874995\nRunning Average TRAIN F1-Score :  0.20651188348843294\nRunning Average VAL Loss :  129.0312761579241\nRunning Average VAL F1-Score :  0.19207158498466015\n\n\nEPOCH  15\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  128.159089940967\nRunning Average TRAIN F1-Score :  0.20753209196934194\nRunning Average VAL Loss :  129.05208574022566\nRunning Average VAL F1-Score :  0.19280411888446128\n\n\nEPOCH  16\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:44<00:00, 23.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  128.07091607469502\nRunning Average TRAIN F1-Score :  0.20841132529136358\nRunning Average VAL Loss :  128.83642101287842\nRunning Average VAL F1-Score :  0.19366810470819473\n\n\nEPOCH  17\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:44<00:00, 23.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.99045710852651\nRunning Average TRAIN F1-Score :  0.209959879856218\nRunning Average VAL Loss :  129.13444914136613\nRunning Average VAL F1-Score :  0.19486841612628528\n\n\nEPOCH  18\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.91688354810078\nRunning Average TRAIN F1-Score :  0.21017102538749124\nRunning Average VAL Loss :  129.09949398040771\nRunning Average VAL F1-Score :  0.19697332648294313\n\n\nEPOCH  19\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:44<00:00, 23.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.7109381719069\nRunning Average TRAIN F1-Score :  0.21193268262978757\nRunning Average VAL Loss :  128.83574540274483\nRunning Average VAL F1-Score :  0.19396526286644594\n\n\nEPOCH  20\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:45<00:00, 23.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.6863477230072\nRunning Average TRAIN F1-Score :  0.21245509331029924\nRunning Average VAL Loss :  128.93520205361503\nRunning Average VAL F1-Score :  0.19535395982010023\n\n\nEPOCH  21\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:44<00:00, 23.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.65867590181756\nRunning Average TRAIN F1-Score :  0.21241225983778184\nRunning Average VAL Loss :  128.6876839229039\nRunning Average VAL F1-Score :  0.19563207801963603\n\n\nEPOCH  22\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:44<00:00, 23.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.66321536988923\nRunning Average TRAIN F1-Score :  0.21243242321140837\nRunning Average VAL Loss :  128.9073532649449\nRunning Average VAL F1-Score :  0.19624777430934565\n\n\nEPOCH  23\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:46<00:00, 22.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.65119189927073\nRunning Average TRAIN F1-Score :  0.21269499566970448\nRunning Average VAL Loss :  128.88768305097307\nRunning Average VAL F1-Score :  0.19474040583840438\n\n\nEPOCH  24\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:44<00:00, 23.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.65395657943957\nRunning Average TRAIN F1-Score :  0.21236839286531461\nRunning Average VAL Loss :  128.89639486585344\nRunning Average VAL F1-Score :  0.1962287463247776\n\n\nEPOCH  25\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1056/1056 [00:44<00:00, 23.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Running Average TRAIN Loss :  127.65266032652421\nRunning Average TRAIN F1-Score :  0.2125067676586861\nRunning Average VAL Loss :  128.90435246058874\nRunning Average VAL F1-Score :  0.19544664131743567\n\n\nTRAINING FINISHED\nFINAL TRAINING SCORE :  0.2125067676586861\nFINAL VALIDATION SCORE :  0.19544664131743567\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict():\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n        \n    model.eval()\n    \n    labels = pd.read_csv(paths.train_labels_path, sep = \"\\t\")\n    top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n    labels_names = top_terms[:config.num_labels].index.values\n    print(\"GENERATE PREDICTION FOR TEST SET...\")\n\n    ids_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n    go_terms_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=object)\n    confs_ = np.empty(shape=(len(test_dataloader)*config.num_labels,), dtype=np.float32)\n\n    for i, (embed, id) in tqdm(enumerate(test_dataloader)):\n        embed = embed.to(config.device)\n        confs_[i*config.num_labels:(i+1)*config.num_labels] = torch.nn.functional.sigmoid(model(embed)).squeeze().detach().cpu().numpy()\n        ids_[i*config.num_labels:(i+1)*config.num_labels] = id[0]\n        go_terms_[i*config.num_labels:(i+1)*config.num_labels] = labels_names\n\n    submission_df = pd.DataFrame(data={\"Id\" : ids_, \"GO term\" : go_terms_, \"Confidence\" : confs_})\n    print(\"PREDICTIONS DONE\")\n    return submission_df","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:34:02.290193Z","iopub.execute_input":"2023-06-10T16:34:02.290696Z","iopub.status.idle":"2023-06-10T16:34:02.304116Z","shell.execute_reply.started":"2023-06-10T16:34:02.290648Z","shell.execute_reply":"2023-06-10T16:34:02.302476Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"submission_df = predict()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:34:02.305610Z","iopub.execute_input":"2023-06-10T16:34:02.305962Z","iopub.status.idle":"2023-06-10T16:35:52.103060Z","shell.execute_reply.started":"2023-06-10T16:34:02.305925Z","shell.execute_reply":"2023-06-10T16:35:52.101940Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"GENERATE PREDICTION FOR TEST SET...\n","output_type":"stream"},{"name":"stderr","text":"141865it [01:40, 1408.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"PREDICTIONS DONE\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_df.head(50)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:35:52.104534Z","iopub.execute_input":"2023-06-10T16:35:52.104992Z","iopub.status.idle":"2023-06-10T16:35:52.121743Z","shell.execute_reply.started":"2023-06-10T16:35:52.104959Z","shell.execute_reply":"2023-06-10T16:35:52.120759Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"        Id     GO term  Confidence\n0   Q9CQV8  GO:0005575    0.876242\n1   Q9CQV8  GO:0008150    0.887685\n2   Q9CQV8  GO:0110165    0.871613\n3   Q9CQV8  GO:0003674    0.881831\n4   Q9CQV8  GO:0005622    0.848041\n5   Q9CQV8  GO:0009987    0.837071\n6   Q9CQV8  GO:0043226    0.808521\n7   Q9CQV8  GO:0043229    0.790866\n8   Q9CQV8  GO:0005488    0.879563\n9   Q9CQV8  GO:0043227    0.787817\n10  Q9CQV8  GO:0005737    0.847304\n11  Q9CQV8  GO:0043231    0.762840\n12  Q9CQV8  GO:0005515    0.864110\n13  Q9CQV8  GO:0065007    0.850178\n14  Q9CQV8  GO:0050789    0.849397\n15  Q9CQV8  GO:0050794    0.831501\n16  Q9CQV8  GO:0050896    0.727176\n17  Q9CQV8  GO:0008152    0.465157\n18  Q9CQV8  GO:0032501    0.757813\n19  Q9CQV8  GO:0005634    0.612994\n20  Q9CQV8  GO:0032502    0.785470\n21  Q9CQV8  GO:0071704    0.392033\n22  Q9CQV8  GO:0048856    0.773448\n23  Q9CQV8  GO:0016020    0.662753\n24  Q9CQV8  GO:0003824    0.410100\n25  Q9CQV8  GO:0044237    0.367996\n26  Q9CQV8  GO:0044238    0.351197\n27  Q9CQV8  GO:0007275    0.725404\n28  Q9CQV8  GO:0006807    0.318864\n29  Q9CQV8  GO:0071944    0.672314\n30  Q9CQV8  GO:0071840    0.609753\n31  Q9CQV8  GO:0019222    0.760205\n32  Q9CQV8  GO:0016043    0.611190\n33  Q9CQV8  GO:0048518    0.722313\n34  Q9CQV8  GO:0005829    0.706110\n35  Q9CQV8  GO:0043170    0.393311\n36  Q9CQV8  GO:0048731    0.683988\n37  Q9CQV8  GO:0060255    0.733570\n38  Q9CQV8  GO:0051716    0.647754\n39  Q9CQV8  GO:0005886    0.609325\n40  Q9CQV8  GO:0032991    0.606939\n41  Q9CQV8  GO:0043228    0.523368\n42  Q9CQV8  GO:0043232    0.516895\n43  Q9CQV8  GO:0031974    0.327642\n44  Q9CQV8  GO:0043233    0.328544\n45  Q9CQV8  GO:0070013    0.331013\n46  Q9CQV8  GO:0048519    0.761612\n47  Q9CQV8  GO:0048522    0.690654\n48  Q9CQV8  GO:0080090    0.711894\n49  Q9CQV8  GO:0031323    0.712469","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>GO term</th>\n      <th>Confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005575</td>\n      <td>0.876242</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q9CQV8</td>\n      <td>GO:0008150</td>\n      <td>0.887685</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q9CQV8</td>\n      <td>GO:0110165</td>\n      <td>0.871613</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q9CQV8</td>\n      <td>GO:0003674</td>\n      <td>0.881831</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005622</td>\n      <td>0.848041</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Q9CQV8</td>\n      <td>GO:0009987</td>\n      <td>0.837071</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Q9CQV8</td>\n      <td>GO:0043226</td>\n      <td>0.808521</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Q9CQV8</td>\n      <td>GO:0043229</td>\n      <td>0.790866</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005488</td>\n      <td>0.879563</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Q9CQV8</td>\n      <td>GO:0043227</td>\n      <td>0.787817</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005737</td>\n      <td>0.847304</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Q9CQV8</td>\n      <td>GO:0043231</td>\n      <td>0.762840</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005515</td>\n      <td>0.864110</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Q9CQV8</td>\n      <td>GO:0065007</td>\n      <td>0.850178</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Q9CQV8</td>\n      <td>GO:0050789</td>\n      <td>0.849397</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Q9CQV8</td>\n      <td>GO:0050794</td>\n      <td>0.831501</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Q9CQV8</td>\n      <td>GO:0050896</td>\n      <td>0.727176</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Q9CQV8</td>\n      <td>GO:0008152</td>\n      <td>0.465157</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Q9CQV8</td>\n      <td>GO:0032501</td>\n      <td>0.757813</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005634</td>\n      <td>0.612994</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Q9CQV8</td>\n      <td>GO:0032502</td>\n      <td>0.785470</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Q9CQV8</td>\n      <td>GO:0071704</td>\n      <td>0.392033</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Q9CQV8</td>\n      <td>GO:0048856</td>\n      <td>0.773448</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Q9CQV8</td>\n      <td>GO:0016020</td>\n      <td>0.662753</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Q9CQV8</td>\n      <td>GO:0003824</td>\n      <td>0.410100</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Q9CQV8</td>\n      <td>GO:0044237</td>\n      <td>0.367996</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Q9CQV8</td>\n      <td>GO:0044238</td>\n      <td>0.351197</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Q9CQV8</td>\n      <td>GO:0007275</td>\n      <td>0.725404</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Q9CQV8</td>\n      <td>GO:0006807</td>\n      <td>0.318864</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Q9CQV8</td>\n      <td>GO:0071944</td>\n      <td>0.672314</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Q9CQV8</td>\n      <td>GO:0071840</td>\n      <td>0.609753</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Q9CQV8</td>\n      <td>GO:0019222</td>\n      <td>0.760205</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Q9CQV8</td>\n      <td>GO:0016043</td>\n      <td>0.611190</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Q9CQV8</td>\n      <td>GO:0048518</td>\n      <td>0.722313</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005829</td>\n      <td>0.706110</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Q9CQV8</td>\n      <td>GO:0043170</td>\n      <td>0.393311</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Q9CQV8</td>\n      <td>GO:0048731</td>\n      <td>0.683988</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Q9CQV8</td>\n      <td>GO:0060255</td>\n      <td>0.733570</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Q9CQV8</td>\n      <td>GO:0051716</td>\n      <td>0.647754</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Q9CQV8</td>\n      <td>GO:0005886</td>\n      <td>0.609325</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Q9CQV8</td>\n      <td>GO:0032991</td>\n      <td>0.606939</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Q9CQV8</td>\n      <td>GO:0043228</td>\n      <td>0.523368</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Q9CQV8</td>\n      <td>GO:0043232</td>\n      <td>0.516895</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Q9CQV8</td>\n      <td>GO:0031974</td>\n      <td>0.327642</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Q9CQV8</td>\n      <td>GO:0043233</td>\n      <td>0.328544</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Q9CQV8</td>\n      <td>GO:0070013</td>\n      <td>0.331013</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Q9CQV8</td>\n      <td>GO:0048519</td>\n      <td>0.761612</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Q9CQV8</td>\n      <td>GO:0048522</td>\n      <td>0.690654</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Q9CQV8</td>\n      <td>GO:0080090</td>\n      <td>0.711894</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Q9CQV8</td>\n      <td>GO:0031323</td>\n      <td>0.712469</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(submission_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:35:52.123051Z","iopub.execute_input":"2023-06-10T16:35:52.123637Z","iopub.status.idle":"2023-06-10T16:35:52.137187Z","shell.execute_reply.started":"2023-06-10T16:35:52.123606Z","shell.execute_reply":"2023-06-10T16:35:52.136161Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"70932500"},"metadata":{}}]},{"cell_type":"code","source":"submission_df.to_csv('submission.tsv', sep='\\t', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T16:35:52.138956Z","iopub.execute_input":"2023-06-10T16:35:52.139337Z","iopub.status.idle":"2023-06-10T16:38:52.477034Z","shell.execute_reply.started":"2023-06-10T16:35:52.139307Z","shell.execute_reply":"2023-06-10T16:38:52.476166Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}